# Meeting Co-Pilot ‚Äî Technology Stack Guide

**Version**: 1.0
**Last Updated**: Dec 24, 2025
**Audience**: Technical stakeholders, developers, senior management

---

## Table of Contents

1. [Overview](#overview)
2. [Frontend Stack](#frontend-stack)
3. [Backend Stack](#backend-stack)
4. [AI & Machine Learning](#ai--machine-learning)
5. [Data Storage](#data-storage)
6. [Real-Time Communication](#real-time-communication)
7. [Audio Processing](#audio-processing)
8. [Development & Deployment](#development--deployment)
9. [Complete Technology Diagram](#complete-technology-diagram)

---

## Overview

Meeting Co-Pilot uses a modern, proven technology stack optimized for:
- **Real-time collaboration** (WebSocket-based)
- **AI-powered features** (Whisper, LLMs)
- **Fast development** (TypeScript, Python)
- **Privacy-first** (local processing options)

**Architecture Pattern**: Client-Server with Real-Time Sync

```
Browser (Next.js) ‚Üê‚Üí WebSocket ‚Üê‚Üí FastAPI Server ‚Üê‚Üí Whisper.cpp / LLMs
                                          ‚Üì
                                   SQLite + VectorDB
```

---

## Frontend Stack

### 1. **Next.js 14** (React Framework)

**What it is**: Full-stack React framework with server-side rendering and API routes

**What it does**:
- Renders the web UI (meeting interface, transcript view, controls)
- Handles client-side routing (`/meeting/[id]`, `/history`)
- Manages browser audio capture (getUserMedia API)
- Sends/receives real-time data via WebSocket

**Why we use it**:
- ‚úÖ **Production-proven**: Used by Vercel, Netflix, Twitch
- ‚úÖ **Fast page loads**: Server-side rendering improves initial load time
- ‚úÖ **Built-in routing**: File-based routing reduces boilerplate
- ‚úÖ **TypeScript support**: Type safety across frontend/backend
- ‚úÖ **Already in Meetily**: 60% of UI components can be reused

**Alternatives considered**: Vite + React (more manual setup), SvelteKit (smaller ecosystem)

---

### 2. **React 18** (UI Library)

**What it is**: JavaScript library for building user interfaces with components

**What it does**:
- Creates reusable UI components (TranscriptView, ParticipantList, ActionPanel)
- Manages UI state (recording status, participant list, transcript updates)
- Handles user interactions (click "Catch Me Up", ask AI questions)

**Why we use it**:
- ‚úÖ **Component-based**: Easy to build complex UIs from small pieces
- ‚úÖ **Large ecosystem**: Thousands of ready-to-use component libraries
- ‚úÖ **Concurrent rendering**: React 18 handles real-time updates efficiently
- ‚úÖ **Familiar**: Most developers know React

**Key React features we use**:
- **Hooks**: `useState`, `useEffect`, `useContext` for state management
- **Context API**: Share meeting state across components without prop drilling
- **Suspense**: Handle async data loading gracefully

---

### 3. **TypeScript** (Programming Language)

**What it is**: JavaScript with static type checking

**What it does**:
- Catches bugs at compile-time (e.g., passing wrong type to function)
- Provides autocomplete and IntelliSense in VS Code
- Documents code with type annotations

**Why we use it**:
- ‚úÖ **Fewer runtime errors**: Type errors caught before deployment
- ‚úÖ **Better DX**: Autocomplete makes development faster
- ‚úÖ **Self-documenting**: Types serve as inline documentation
- ‚úÖ **Refactoring safety**: Renaming variables updates all references

**Example**:
```typescript
interface Transcript {
  id: string;
  text: string;
  speaker: string;
  timestamp: Date;
}

function addTranscript(transcript: Transcript) {
  // TypeScript ensures transcript has correct shape
}
```

---

### 4. **Tailwind CSS** (Styling Framework)

**What it is**: Utility-first CSS framework

**What it does**:
- Styles UI components with utility classes
- Ensures consistent spacing, colors, typography
- Provides responsive design utilities

**Why we use it**:
- ‚úÖ **Fast styling**: Write CSS directly in JSX
- ‚úÖ **Consistent design**: Predefined design tokens (colors, spacing)
- ‚úÖ **Small bundle**: Tree-shakes unused styles
- ‚úÖ **Already in Meetily**: Keeps UI consistent

**Example**:
```tsx
<button className="bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded">
  Start Recording
</button>
```

---

### 5. **pnpm** (Package Manager)

**What it is**: Fast, disk-efficient package manager (alternative to npm/yarn)

**What it does**:
- Installs JavaScript dependencies (React, Next.js, etc.)
- Manages project dependencies and versions
- Creates symlinks to save disk space

**Why we use it**:
- ‚úÖ **Faster installs**: 2-3x faster than npm
- ‚úÖ **Disk efficient**: Shared dependencies across projects
- ‚úÖ **Already in Meetily**: Keeps tooling consistent

---

## Backend Stack

### 6. **FastAPI** (Python Web Framework)

**What it is**: Modern, fast Python web framework for building APIs

**What it does**:
- Handles HTTP requests (create meeting, get transcript, etc.)
- Manages WebSocket connections for real-time sync
- Orchestrates audio processing and AI services
- Serves meeting data from database

**Why we use it**:
- ‚úÖ **Fast development**: Auto-generates API docs (Swagger UI)
- ‚úÖ **Async support**: Non-blocking I/O for WebSocket and AI calls
- ‚úÖ **Type hints**: Python 3.11+ type hints prevent bugs
- ‚úÖ **AI/ML ecosystem**: Easy integration with Whisper, LLMs
- ‚úÖ **Already in Meetily**: Backend is fully functional

**Example**:
```python
@app.websocket("/ws/audio")
async def websocket_audio_endpoint(websocket: WebSocket):
    await websocket.accept()
    while True:
        audio_chunk = await websocket.receive_bytes()
        transcript = await process_audio(audio_chunk)
        await websocket.send_json({"text": transcript})
```

**API Documentation**: Auto-generated at `http://localhost:5167/docs`

---

### 7. **Python 3.11+** (Programming Language)

**What it is**: High-level programming language

**What it does**:
- Runs backend server (FastAPI)
- Processes audio (conversion, streaming)
- Interfaces with AI models (Whisper, LLMs)
- Database operations (SQLite queries)

**Why we use it**:
- ‚úÖ **Rich AI ecosystem**: Whisper, Ollama, pydantic-ai all use Python
- ‚úÖ **Fast development**: Clean syntax, huge standard library
- ‚úÖ **Async/await**: Built-in async support for WebSockets
- ‚úÖ **Type hints**: Modern Python has type safety

**Version requirement**: Python 3.11+ for performance improvements

---

### 8. **Uvicorn** (ASGI Server)

**What it is**: Lightning-fast ASGI server for Python

**What it does**:
- Runs the FastAPI application
- Handles HTTP and WebSocket connections
- Manages concurrent requests

**Why we use it**:
- ‚úÖ **Fast**: Built on uvloop (faster event loop)
- ‚úÖ **WebSocket support**: Native WebSocket handling
- ‚úÖ **Production-ready**: Used by major companies

**Command**: `uvicorn app.main:app --host 0.0.0.0 --port 5167`

---

## AI & Machine Learning

### 9. **Whisper.cpp** (Speech-to-Text Engine)

**What it is**: C++ implementation of OpenAI's Whisper model (optimized for CPU/GPU)

**What it does**:
- Converts audio (WAV files) to text transcripts
- Performs speaker diarization (identifies Speaker 1, 2, 3...)
- Runs locally on server (no cloud API calls)

**Why we use it**:
- ‚úÖ **Fast**: GPU-accelerated (CUDA/Metal support)
- ‚úÖ **Accurate**: OpenAI Whisper is state-of-the-art
- ‚úÖ **Privacy**: Runs locally, no audio sent to cloud
- ‚úÖ **Free**: No API costs
- ‚úÖ **Already in Meetily**: Fully integrated and working

**Model options**:
- `tiny` (75 MB) ‚Äî Fast, lower accuracy
- `small` (466 MB) ‚Äî ‚≠ê **Recommended** for development
- `medium` (1.5 GB) ‚Äî Higher accuracy
- `large-v3` (3 GB) ‚Äî Best accuracy, slower

**Latency**: < 2 seconds for 30-second audio chunk

**API Endpoint**: `http://localhost:8178` (HTTP POST with WAV file)

---

### 10. **Claude API** (Cloud LLM - Primary/Default)

**What it is**: Anthropic's high-quality language model API

**What it does**:
- Provides high-quality AI responses (default system)
- Handles all AI features (summarization, Q&A, extraction)
- Streams audio/transcript data to cloud instantly
- Prevents data loss on browser crash

**Why we use it as PRIMARY**:
- ‚úÖ **Enterprise-grade**: Data NOT used for training (contractual guarantee)
- ‚úÖ **High quality**: Best-in-class reasoning and summarization
- ‚úÖ **Reliable**: Cloud-based, always available, no setup needed
- ‚úÖ **Fast**: Lower latency than local LLMs
- ‚úÖ **Real-time Cloud Sync**: Audio/transcript streams to cloud ‚Üí no data loss on crash

**When used**:
- **Default mode** for all users
- All AI features (Catch Me Up, Q&A, extraction, summaries)
- Real-time sync to prevent data loss

**Cost**: Pay-per-token (acceptable for office deployment)

**NFR Requirement**: Per NFR2, Claude/OpenAI ensures enterprise-grade quality and real-time cloud sync

---

### 11. **Ollama** (Local LLM Runtime - Optional Privacy Mode)

**What it is**: Run large language models locally (like Docker for LLMs)

**What it does**:
- Runs LLMs locally (Llama 3.1, Mistral, etc.) when user enables "Privacy Toggle"
- Provides OpenAI-compatible API
- Handles model loading and inference
- Keeps all data on-premises

**Why we offer it as OPTIONAL**:
- ‚úÖ **Privacy**: All AI processing stays local (for privacy-conscious users)
- ‚úÖ **Cost**: No API fees (for cost-sensitive deployments)
- ‚úÖ **Offline**: Works without internet
- ‚úÖ **GPU-accelerated**: Fast inference with CUDA/Metal

**When used**:
- User explicitly enables "Privacy Toggle" in settings
- Compliance requirements mandate on-premises processing
- Cost optimization for high-volume usage

**Trade-offs**:
- ‚ö†Ô∏è **Lower quality**: Local models are less capable than Claude
- ‚ö†Ô∏è **Slower**: Inference takes longer (especially without GPU)
- ‚ö†Ô∏è **No cloud sync**: Data loss possible on browser crash
- ‚ö†Ô∏è **Setup required**: Need to download models, configure GPU

**Example models**:
- `llama3.1:8b` ‚Äî Fast, good for real-time features
- `mistral:7b` ‚Äî Efficient, good balance
- `gemma:7b` ‚Äî Lightweight

**System Default**: Claude API (can switch to Ollama via Privacy Toggle)

---

### 12. **pydantic-ai** (AI Orchestration Framework)

**What it is**: Python framework for structured AI interactions

**What it does**:
- Manages LLM calls (Ollama, Claude, OpenAI)
- Enforces structured outputs (JSON schemas)
- Handles prompt templates
- Switches between providers seamlessly

**Why we use it**:
- ‚úÖ **Type-safe**: Pydantic models ensure correct AI output
- ‚úÖ **Multi-provider**: Easy to switch Ollama ‚Üî Claude
- ‚úÖ **Already in Meetily**: Fully integrated

**Example**:
```python
from pydantic_ai import Agent

class ActionItem(BaseModel):
    task: str
    owner: str
    deadline: str

agent = Agent(model="ollama:llama3.1")
result = await agent.run(
    "Extract action items from transcript",
    response_type=list[ActionItem]
)
```

---

## Data Storage

### 13. **SQLite** (Relational Database)

**What it is**: Serverless SQL database (single file)

**What it does**:
- Stores meetings metadata (title, date, duration)
- Stores transcripts (speaker, text, timestamp)
- Stores action items and decisions
- Stores participant information

**Why we use it**:
- ‚úÖ **Simple**: No database server required
- ‚úÖ **Fast**: Direct file access, no network latency
- ‚úÖ **Reliable**: ACID-compliant transactions
- ‚úÖ **Portable**: Single file, easy backup
- ‚úÖ **Good for MVP**: Easy to migrate to PostgreSQL later

**Database schema** (simplified):
```sql
meetings (id, title, start_time, end_time, status)
transcripts (id, meeting_id, speaker, text, timestamp)
action_items (id, meeting_id, task, owner, deadline, status)
decisions (id, meeting_id, decision_text, timestamp)
participants (id, meeting_id, name, joined_at, role)
```

**Migration path**: Can switch to PostgreSQL for multi-tenant deployment

---

### 14. **aiosqlite** (Async SQLite Library)

**What it is**: Async wrapper for SQLite

**What it does**:
- Enables non-blocking database queries
- Works with FastAPI's async/await
- Prevents database from blocking WebSocket connections

**Why we use it**:
- ‚úÖ **Non-blocking**: Database queries don't block real-time features
- ‚úÖ **FastAPI compatible**: Works with async endpoints
- ‚úÖ **Already in Meetily**: No changes needed

---

### 15. **ChromaDB** (Vector Database)

**What it is**: Embedding database for semantic search

**What it does**:
- Stores meeting embeddings (vector representations)
- Enables semantic search ("What did we decide about pricing?")
- Powers cross-meeting context (searches past meetings)
- Enables Q&A with source citations

**Why we use it**:
- ‚úÖ **Embedded**: No external server (like SQLite for vectors)
- ‚úÖ **Fast**: Optimized for similarity search
- ‚úÖ **Python-native**: Easy FastAPI integration
- ‚úÖ **Free**: Open-source

**How it works**:
1. Meeting transcript ‚Üí Split into chunks
2. Each chunk ‚Üí Convert to embedding (vector)
3. Store in ChromaDB with metadata (meeting_id, timestamp)
4. User asks question ‚Üí Convert to embedding ‚Üí Find similar chunks
5. Return relevant transcript sections with source citations

**Alternative**: LanceDB (similar, more features)

**Phase**: Implemented in Phase 4

---

## Real-Time Communication

### 16. **WebSocket** (Real-Time Protocol)

**What it is**: Bidirectional communication protocol (upgrade from HTTP)

**What it does**:
- Streams audio from browser to backend
- Broadcasts transcript updates to all participants
- Sends real-time AI responses (Q&A, summaries)
- Notifies participants of join/leave events

**Why we use it**:
- ‚úÖ **Bidirectional**: Server can push updates to clients
- ‚úÖ **Low latency**: No polling overhead
- ‚úÖ **Native browser support**: All modern browsers support WebSocket
- ‚úÖ **FastAPI support**: Built-in WebSocket endpoints

**Example flow**:
```
Browser ‚Üí WebSocket ‚Üí Backend ‚Üí Process ‚Üí Broadcast to all participants
```

**Connection management**: Auto-reconnect on disconnect

---

### 17. **Socket.IO** (WebSocket Library - Optional)

**What it is**: Enhanced WebSocket library with fallbacks

**What it does**:
- Manages WebSocket connections with reconnection logic
- Provides room-based broadcasting (per-meeting isolation)
- Falls back to polling if WebSocket unavailable

**Why we might use it**:
- ‚úÖ **Automatic reconnection**: Handles network issues gracefully
- ‚úÖ **Room support**: Easy to broadcast to specific meetings
- ‚úÖ **Fallback**: Works even if WebSocket is blocked

**Phase**: May add in Phase 2 if native WebSocket has issues

---

## Audio Processing

### 18. **MediaRecorder API** (Browser API)

**What it is**: Built-in browser API for recording audio

**What it does**:
- Captures microphone input in browser
- Encodes audio to WebM/Opus format
- Provides audio chunks in real-time

**Why we use it**:
- ‚úÖ **Native browser API**: No library needed
- ‚úÖ **Modern**: Supported in all major browsers
- ‚úÖ **Efficient**: Hardware-accelerated encoding

**Replaces**: Tauri's Rust audio capture

**Browser support**: Chrome, Firefox, Safari, Edge (latest versions)

---

### 19. **getUserMedia API** (Browser API)

**What it is**: Browser API for accessing microphone/camera

**What it does**:
- Requests microphone permission from user
- Provides audio stream (MediaStream)
- Lists available audio input devices

**Why we use it**:
- ‚úÖ **Standard**: Part of WebRTC spec
- ‚úÖ **Secure**: Requires HTTPS and user permission
- ‚úÖ **Device selection**: User can choose specific microphone

**Example**:
```typescript
const stream = await navigator.mediaDevices.getUserMedia({
  audio: {
    echoCancellation: true,
    noiseSuppression: true,
    sampleRate: 16000
  }
});
```

---

### 20. **ffmpeg** (Audio Conversion Tool)

**What it is**: Swiss Army knife for audio/video processing

**What it does**:
- Converts WebM (from browser) ‚Üí WAV (for Whisper)
- Resamples audio to 16kHz mono (Whisper requirement)
- Processes audio chunks in real-time

**Why we use it**:
- ‚úÖ **Format conversion**: Browser outputs WebM, Whisper needs WAV
- ‚úÖ **Fast**: Hardware-accelerated
- ‚úÖ **Reliable**: Industry-standard tool
- ‚úÖ **Free**: Open-source

**Command example**:
```bash
ffmpeg -i input.webm -ar 16000 -ac 1 -f wav output.wav
```

**Phase**: Critical for Phase 1 (browser audio ‚Üí Whisper)

---

## Development & Deployment

### 21. **Docker** (Containerization)

**What it is**: Platform for running applications in containers

**What it does**:
- Packages backend + Whisper + dependencies
- Ensures consistent environment (dev = prod)
- Simplifies deployment

**Why we use it**:
- ‚úÖ **Consistent**: Same environment on all machines
- ‚úÖ **Isolated**: No dependency conflicts
- ‚úÖ **Easy deployment**: Single `docker-compose up`
- ‚úÖ **Already in Meetily**: Docker setup works perfectly

**Containers**:
- `backend`: FastAPI server (port 5167)
- `whisper`: Whisper.cpp server (port 8178)

**Command**: `./run-docker.sh`

---

### 22. **Docker Compose** (Multi-Container Orchestration)

**What it is**: Tool for defining multi-container Docker applications

**What it does**:
- Starts backend + Whisper together
- Manages networking between containers
- Handles environment variables

**Why we use it**:
- ‚úÖ **Simple**: One command to start all services
- ‚úÖ **Declarative**: Config in `docker-compose.yml`

---

### 23. **Git** (Version Control)

**What it is**: Distributed version control system

**What it does**:
- Tracks code changes
- Enables collaboration
- Provides rollback capability

**Why we use it**:
- ‚úÖ **Industry standard**: Everyone knows Git
- ‚úÖ **GitHub integration**: Easy to share/review code
- ‚úÖ **Branch strategy**: Feature branches for each phase

---

### 24. **VS Code** (Code Editor)

**What it is**: Popular code editor from Microsoft

**Why we use it**:
- ‚úÖ **TypeScript support**: Best-in-class TypeScript tooling
- ‚úÖ **Extensions**: Python, React, Docker extensions
- ‚úÖ **Integrated terminal**: Run commands without leaving editor
- ‚úÖ **Git integration**: Built-in Git GUI

---

## Complete Technology Diagram

### Full Stack Visualization

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         FRONTEND (Browser)                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Next.js 14 + React 18 + TypeScript                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Tailwind CSS (styling)                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - getUserMedia API (mic access)                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - MediaRecorder API (audio capture)                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - WebSocket client (real-time)                          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì WebSocket / HTTP
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      BACKEND (FastAPI Server)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  FastAPI + Python 3.11 + Uvicorn                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - WebSocket handler (real-time sync)                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Session management                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Audio processing (ffmpeg conversion)                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - AI orchestration (pydantic-ai)                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                              ‚Üì                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   SQLite     ‚îÇ  ‚îÇ  ChromaDB    ‚îÇ  ‚îÇ  Whisper.cpp      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  (meetings,  ‚îÇ  ‚îÇ  (embeddings,‚îÇ  ‚îÇ  (transcription)  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  transcripts)‚îÇ  ‚îÇ   vectors)   ‚îÇ  ‚îÇ  Port 8178        ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì API calls
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         AI PROVIDERS                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ  Claude API  ‚îÇ                    ‚îÇ   Ollama     ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ (PRIMARY/    ‚îÇ                    ‚îÇ  (Optional   ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  Default)    ‚îÇ                    ‚îÇ  Privacy     ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ                    ‚îÇ  Toggle)     ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

DEPLOYMENT LAYER:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Docker + Docker Compose                                         ‚îÇ
‚îÇ  - backend container (FastAPI)                                   ‚îÇ
‚îÇ  - whisper container (Whisper.cpp)                               ‚îÇ
‚îÇ  - Volume mounts (SQLite, models)                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Technology Decision Summary

| Category | Technology | Why Chosen | Phase Used |
|----------|-----------|------------|------------|
| **Frontend Framework** | Next.js 14 | Server-side rendering, built-in routing, already in Meetily | All |
| **UI Library** | React 18 | Component-based, large ecosystem, concurrent rendering | All |
| **Language (Frontend)** | TypeScript | Type safety, better DX, self-documenting | All |
| **Styling** | Tailwind CSS | Fast styling, consistent design, already in Meetily | All |
| **Package Manager** | pnpm | Faster installs, disk efficient | All |
| **Backend Framework** | FastAPI | Fast development, async, AI-friendly, already in Meetily | All |
| **Language (Backend)** | Python 3.11+ | Rich AI ecosystem, async support | All |
| **Server** | Uvicorn | Fast ASGI server, WebSocket support | All |
| **Transcription** | Whisper.cpp | Local, fast, accurate, free, already in Meetily | 1, 2, 3 |
| **LLM (Primary)** | Claude API | Enterprise-grade, high quality, cloud sync, default system | 3, 4 |
| **LLM (Optional)** | Ollama | Privacy toggle for local-only processing | 3, 4 |
| **AI Framework** | pydantic-ai | Type-safe, multi-provider, already in Meetily | 3, 4 |
| **Database** | SQLite | Simple, fast, portable, already in Meetily | All |
| **Async DB** | aiosqlite | Non-blocking, FastAPI compatible | All |
| **Vector DB** | ChromaDB | Embedded, fast, Python-native | 4 |
| **Real-Time** | WebSocket | Bidirectional, low latency, native browser support | 1, 2, 3 |
| **Audio API** | getUserMedia + MediaRecorder | Native browser APIs, no library needed | 1 |
| **Audio Conversion** | ffmpeg | WebM ‚Üí WAV conversion for Whisper | 1 |
| **Containerization** | Docker + Compose | Consistent environment, easy deployment | All |
| **Version Control** | Git + GitHub | Industry standard, collaboration | All |

---

## Key Technology Trade-offs

### 1. **SQLite vs PostgreSQL**
- **Chose**: SQLite
- **Why**: Simpler for MVP, single-user instance, easy migration path
- **Trade-off**: Won't scale to multi-tenant (acceptable for office deployment)

### 2. **Claude API vs Ollama-only**
- **Chose**: Claude API (primary) + Ollama (optional privacy toggle)
- **Why**: Enterprise-grade quality, cloud sync prevents data loss, reliable
- **Trade-off**: API costs (acceptable for office deployment), requires internet

### 3. **Native WebSocket vs Socket.IO**
- **Chose**: Native WebSocket first
- **Why**: Simpler, no extra dependencies
- **Trade-off**: Manual reconnection logic (can add Socket.IO if needed)

### 4. **Whisper.cpp vs Cloud Transcription**
- **Chose**: Whisper.cpp (local)
- **Why**: Privacy, free, fast with GPU
- **Trade-off**: Requires GPU for best performance (acceptable - office has GPUs)

---

## Technology Maturity & Risk Assessment

| Technology | Maturity | Risk Level | Mitigation |
|------------|----------|------------|------------|
| Next.js 14 | Stable | üü¢ Low | Production-proven, large community |
| FastAPI | Stable | üü¢ Low | Widely used, excellent docs |
| Whisper.cpp | Stable | üü¢ Low | Already working in Meetily |
| Ollama | Growing | üü° Medium | Cloud fallback if issues |
| ChromaDB | Growing | üü° Medium | Can switch to LanceDB/pgvector |
| WebSocket | Stable | üü¢ Low | Native browser support |
| SQLite | Mature | üü¢ Low | Battle-tested, used everywhere |

---

## Development Tools Summary

**Frontend Development**:
```bash
cd frontend
pnpm install          # Install dependencies
pnpm run dev          # Start dev server (http://localhost:3118)
pnpm run build        # Production build
pnpm run type-check   # TypeScript validation
```

**Backend Development**:
```bash
cd backend
./run-docker.sh       # Start backend + Whisper in Docker
# OR manually:
source venv/bin/activate
python app/main.py    # Start FastAPI (http://localhost:5167)
```

**Access Points**:
- Frontend: http://localhost:3118
- Backend API: http://localhost:5167
- API Docs: http://localhost:5167/docs
- Whisper: http://localhost:8178

---

## Learning Resources

**Frontend**:
- Next.js: https://nextjs.org/docs
- React: https://react.dev
- TypeScript: https://www.typescriptlang.org/docs
- Tailwind: https://tailwindcss.com/docs

**Backend**:
- FastAPI: https://fastapi.tiangolo.com
- Python Async: https://docs.python.org/3/library/asyncio.html
- pydantic-ai: https://ai.pydantic.dev

**AI**:
- Whisper.cpp: https://github.com/ggerganov/whisper.cpp
- Ollama: https://ollama.ai/docs
- Claude API: https://docs.anthropic.com

**Databases**:
- SQLite: https://www.sqlite.org/docs.html
- ChromaDB: https://docs.trychroma.com

---

**Document Status**: Complete
**Next Update**: After Phase 1 (if tech stack changes)
**Maintained By**: Meeting Co-Pilot Team
